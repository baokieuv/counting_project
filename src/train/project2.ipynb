{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"6JoC27JzzkBw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744203753194,"user_tz":-420,"elapsed":111032,"user":{"displayName":"bao kieu","userId":"10466398329851117304"}},"outputId":"46088673-b6c7-4a1a-8a82-bbb654d0a8c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.2/112.6 GB disk)\n"]}],"source":["#import library\n","%cd /content/drive/MyDrive/project2/yolov11\n","%pip install \"ultralytics<=8.3.40\" supervision roboflow\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3Ef8yxgovfb","executionInfo":{"status":"ok","timestamp":1744203640807,"user_tz":-420,"elapsed":24179,"user":{"displayName":"bao kieu","userId":"10466398329851117304"}},"outputId":"97bb2076-d544-45c5-cfa5-ae6c1dd96619"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Test\n","!yolo task=detect mode=predict model=yolo11n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yL5fE7nAqGFf","executionInfo":{"status":"ok","timestamp":1744203782170,"user_tz":-420,"elapsed":14144,"user":{"displayName":"bao kieu","userId":"10466398329851117304"}},"outputId":"554b1f48-569a-4dea-f8b2-ebcdc1fed9fc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","\n","Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n","image 1/1 /content/drive/.shortcut-targets-by-id/1FdU2I-LdmRz7q71PJMLrEB2OtePq1c47/project2/yolov11/dog.jpeg: 640x384 2 persons, 1 car, 1 dog, 1 handbag, 58.5ms\n","Speed: 14.7ms preprocess, 58.5ms inference, 410.7ms postprocess per image at shape (1, 3, 640, 384)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","üí° Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","from PIL import Image\n","import requests\n","\n","model = YOLO('yolo11n.pt')\n","image = Image.open(requests.get('https://media.roboflow.com/notebooks/examples/dog.jpeg', stream=True).raw)\n","result = model.predict(image, conf=0.25)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LxI2gtGrTNk","executionInfo":{"status":"ok","timestamp":1744203789892,"user_tz":-420,"elapsed":2474,"user":{"displayName":"bao kieu","userId":"10466398329851117304"}},"outputId":"07597874-06a1-446b-b1d6-75d251ed24ce"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 640x384 2 persons, 1 car, 1 dog, 1 handbag, 94.2ms\n","Speed: 4.4ms preprocess, 94.2ms inference, 198.0ms postprocess per image at shape (1, 3, 640, 384)\n"]}]},{"cell_type":"markdown","source":["<h2>Download dataset from Roboflow</h2>"],"metadata":{"id":"mvk4Yk_as0O3"}},{"cell_type":"code","source":["dataset = \"/content/drive/MyDrive/project2/yolov11/datasets\""],"metadata":{"id":"OtuMQEzopcbz","executionInfo":{"status":"ok","timestamp":1744203809739,"user_tz":-420,"elapsed":5,"user":{"displayName":"bao kieu","userId":"10466398329851117304"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#T·∫£i datasets\n","!mkdir /content/drive/MyDrive/project2/yolov11/datasets\n","%cd /content/drive/MyDrive/project2/yolov11/datasets\n","\n","from google.colab import userdata\n","from roboflow import Roboflow\n","\n","rf = Roboflow(api_key=\"53ePTntjIYJ9MfOSYyg5\")\n","project = rf.workspace(\"test-ujumv\").project(\"washer-qu1ns\")\n","version = project.version(1)\n","dataset = version.download(\"yolov11\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRyrRjCLhqQ_","executionInfo":{"status":"ok","timestamp":1744185283311,"user_tz":-420,"elapsed":84183,"user":{"displayName":"B·∫£o Ki·ªÅu","userId":"03395151877717480798"}},"outputId":"bc3c4edb-6d85-419c-e55e-0acd663a0f6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/project2/yolov11/datasets\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in washer-1 to yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162477/162477 [00:12<00:00, 12704.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to washer-1 in yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9600/9600 [01:09<00:00, 138.99it/s]\n"]}]},{"cell_type":"markdown","source":["<h1>Train Settings</h1>\n","<h3>Some typical arguments</h3>\n","<table>\n","  <tr>\n","    <th>Argument</th>\n","    <th>Type</th>\n","    <th>Default</th>\n","    <th>Description</th>\n","  </tr>\n","  <tr>\n","    <td>model</td>\n","    <td>str</td>\n","    <td>None</td>\n","    <td>Specifies the model file for training. Accepts a path to either a .pt pretrained model or a .yaml configuration file. Essential for defining the model structure or initializing weights.</td>\n","  </tr>\n","  <tr>\n","    <td>data</td>\n","    <td>str</td>\n","    <td>None</td>\n","    <td>Path to the dataset configuration file (e.g., coco8.yaml). This file contains dataset-specific parameters, including paths to training and validation data, class names, and number of classes.</td>\n","  </tr>\n","  <tr>\n","    <td>epochs</td>\n","    <td>int</td>\n","    <td>100</td>\n","    <td>Total number of training epochs. Each epoch represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance.</td>\n","  </tr>\n","  <tr>\n","    <td>batch</td>\n","    <td>int</td>\n","    <td>16</td>\n","    <td>Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).</td>\n","  </tr>\n","  <tr>\n","    <td>imgsz</td>\n","    <td>int or list</td>\n","    <td>640</td>\n","    <td>Target image size for training. All images are resized to this dimension before being fed into the model. Affects model accuracy and computational complexity.</td>\n","  </tr>\n","  <tr>\n","    <td>optimizer</td>\n","    <td>str</td>\n","    <td>'auto'</td>\n","    <td>Choice of optimizer for training. Options include SGD, Adam, AdamW, NAdam, RAdam, RMSProp etc., or auto for automatic selection based on model configuration. Affects convergence speed and stability.</td>\n","  </tr>\n","  <tr>\n","    <td>resume</td>\n","    <td>bool</td>\n","    <td>False</td>\n","    <td>Resumes training from the last saved checkpoint. Automatically loads model weights, optimizer state, and epoch count, continuing training seamlessly.</td>\n","  </tr>\n","  <tr>\n","    <td>plots</td>\n","    <td>bool</td>\n","    <td>False</td>\n","    <td>Generates and saves plots of training and validation metrics, as well as prediction examples, providing visual insights into model performance and learning progression.</td>\n","  </tr>\n","</table>\n","\n","<p>Link:\n","  <a href=\"https://docs.ultralytics.com/usage/cfg/\">Ultralytics YOLO Docs</a>\n","</p>"],"metadata":{"id":"Uu7XlN7Nkojl"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/project2/yolov11\n","\n","!yolo task=detect mode=train model=/content/drive/MyDrive/project2/yolov11/runs/detect/train/weights/last.pt data=/content/drive/MyDrive/project2/yolov11/datasets/washer-1/data.yaml epochs=400 imgsz=640 plots=True resume=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PexobzFiwzj","outputId":"8b532738-d1b8-4190-d182-3b7a2b17a6fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1FdU2I-LdmRz7q71PJMLrEB2OtePq1c47/project2/yolov11\n","New https://pypi.org/project/ultralytics/8.3.105 available üòÉ Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.40 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/project2/yolov11/runs/detect/train/weights/last.pt, data=/content/drive/MyDrive/project2/yolov11/datasets/washer-1/data.yaml, epochs=400, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/content/drive/MyDrive/project2/yolov11/runs/detect/train/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 117MB/s]\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1744203885.831744    1824 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1744203885.913948    1824 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n"," 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n"," 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n","YOLO11s summary: 319 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n","\n","Transferred 499/499 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1FdU2I-LdmRz7q71PJMLrEB2OtePq1c47/project2/yolov11/datasets/washer-1/train/labels... 3891 images, 1314 backgrounds, 0 corrupt: 100% 3891/3891 [38:45<00:00,  1.67it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1FdU2I-LdmRz7q71PJMLrEB2OtePq1c47/project2/yolov11/datasets/washer-1/train/labels.cache\n","/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n","  A.ImageCompression(quality_lower=75, p=0.0),\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1FdU2I-LdmRz7q71PJMLrEB2OtePq1c47/project2/yolov11/datasets/washer-1/valid/labels... 601 images, 86 backgrounds, 0 corrupt: 100% 601/601 [06:38<00:00,  1.51it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1FdU2I-LdmRz7q71PJMLrEB2OtePq1c47/project2/yolov11/datasets/washer-1/valid/labels.cache\n","WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 11, len(boxes) = 1777. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n","Resuming training /content/drive/MyDrive/project2/yolov11/runs/detect/train/weights/last.pt from epoch 101 to 400 total epochs\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 400 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    101/400      4.96G     0.6154     0.2995      0.917         18        640: 100% 244/244 [01:37<00:00,  2.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:09<00:00,  2.01it/s]\n","                   all        601       1777      0.931      0.945      0.946      0.831\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    102/400      4.98G     0.6808      0.325     0.9428         29        640: 100% 244/244 [01:35<00:00,  2.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.58it/s]\n","                   all        601       1777      0.932      0.941       0.94      0.823\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    103/400      5.02G     0.6749     0.3195     0.9375         20        640: 100% 244/244 [01:35<00:00,  2.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:06<00:00,  2.75it/s]\n","                   all        601       1777      0.928      0.941      0.949      0.831\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    104/400      5.33G     0.6749     0.3189     0.9399         19        640: 100% 244/244 [01:36<00:00,  2.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.43it/s]\n","                   all        601       1777       0.94      0.941      0.952      0.841\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    105/400      5.25G     0.6666     0.3212     0.9326         24        640: 100% 244/244 [01:36<00:00,  2.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.20it/s]\n","                   all        601       1777      0.941      0.937      0.943      0.822\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    106/400       4.8G     0.6785     0.3205     0.9409         19        640: 100% 244/244 [01:37<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:06<00:00,  2.73it/s]\n","                   all        601       1777       0.95      0.934      0.949      0.835\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    107/400      5.37G     0.6625     0.3175     0.9368         32        640: 100% 244/244 [01:35<00:00,  2.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.34it/s]\n","                   all        601       1777      0.936      0.943      0.944      0.822\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    108/400      4.58G     0.6697       0.32     0.9349         10        640: 100% 244/244 [01:36<00:00,  2.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:06<00:00,  2.81it/s]\n","                   all        601       1777      0.934       0.94      0.953       0.83\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    109/400      5.18G     0.6687     0.3168      0.937         27        640: 100% 244/244 [01:36<00:00,  2.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.50it/s]\n","                   all        601       1777      0.939      0.947      0.952      0.838\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    110/400      5.02G     0.6698     0.3198     0.9357         13        640: 100% 244/244 [01:33<00:00,  2.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.36it/s]\n","                   all        601       1777      0.942      0.934      0.944      0.832\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    111/400      5.13G     0.6673     0.3154     0.9351         38        640: 100% 244/244 [01:35<00:00,  2.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.61it/s]\n","                   all        601       1777      0.952      0.929      0.951       0.84\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    112/400      4.75G     0.6555     0.3135     0.9344         11        640: 100% 244/244 [01:35<00:00,  2.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.39it/s]\n","                   all        601       1777      0.928      0.947      0.946      0.832\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    113/400       4.8G     0.6581     0.3129     0.9314         18        640: 100% 244/244 [01:34<00:00,  2.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.36it/s]\n","                   all        601       1777       0.94      0.936      0.945      0.837\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    114/400      4.62G     0.6619     0.3146     0.9326         15        640: 100% 244/244 [01:36<00:00,  2.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.70it/s]\n","                   all        601       1777      0.934      0.939      0.947       0.83\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","    115/400      4.77G      0.658     0.3132     0.9332        134        640:  89% 217/244 [01:26<00:14,  1.85it/s]"]}]},{"cell_type":"markdown","source":["<h2>Results</h2>"],"metadata":{"id":"5AZF0WVmsUZG"}},{"cell_type":"code","source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'/content/drive/MyDrive/project2/yolov11/runs/detect/train/confusion_matrix.png', width=600)"],"metadata":{"id":"mQaBhD9Dr_2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'/content/drive/MyDrive/project2/yolov11/runs/detect/train/results.png', width=600)"],"metadata":{"id":"hHAi02ztsFaN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2>Validate</h2>"],"metadata":{"id":"I_X092nb6wFO"}},{"cell_type":"code","source":["!yolo task=detect mode=val model=/content/drive/MyDrive/project2/yolov11/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"],"metadata":{"id":"YW0iJ3iU6krF"},"execution_count":null,"outputs":[]}]}